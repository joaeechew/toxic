{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    full_path = os.path.join(os.path.realpath('..'), path)\n",
    "    df = pd.read_csv(full_path, header=0, index_col=0)\n",
    "    print(\"Dataset has {} rows, {} columns.\".format(*df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 159571 rows, 7 columns.\n",
      "Dataset has 153164 rows, 1 columns.\n"
     ]
    }
   ],
   "source": [
    "df_train = load_data('data/raw/train.csv')\n",
    "df_test = load_data('data/raw/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN with string \"unknown\"\n",
    "df_train.fillna('unknown',inplace=True)\n",
    "df_test.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"Create features as seen in EDA\"\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    # Uppercase count\n",
    "    df['processed'] = df['comment_text'].str.split()\n",
    "    print(\"Counting uppercases...\")\n",
    "    df['uppercase_count'] = df['processed'].apply(lambda x: sum(1 for t in x if t.isupper() and len(t)>2))\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    \n",
    "    # Bad words\n",
    "    print(\"Counting bad words...\")\n",
    "    path = 'data/external/badwords.txt'\n",
    "    bad_words = []\n",
    "    f = open(os.path.join(os.path.realpath('..'), path), mode='rt', encoding='utf-8')\n",
    "    for line in f:\n",
    "        words = line.split(', ')\n",
    "        for word in words:\n",
    "            word = word.replace('\\n', '')\n",
    "            bad_words.append(word)\n",
    "    f.close()\n",
    "\n",
    "    df['bad_words'] = df['processed'].apply(lambda x: sum(1 for t in x if t in bad_words))\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    \n",
    "    # Count of typos\n",
    "    from enchant.checker import SpellChecker\n",
    "\n",
    "    def typo_count(corpus):\n",
    "        \"Count the number of errors found by pyenchant\"\n",
    "        count = []\n",
    "        for row in corpus:\n",
    "            chkr = SpellChecker(\"en_US\")\n",
    "            chkr.set_text(row)\n",
    "            i = 0\n",
    "            for err in chkr:\n",
    "                i += 1\n",
    "            count.append(i)\n",
    "        return count\n",
    "    \n",
    "    print(\"Counting typos...\")\n",
    "    df['typos'] = typo_count(df.comment_text)\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    \n",
    "    # Doc length\n",
    "    print(\"Counting length of each comment...\")\n",
    "    df['length'] = [len(t) for t in df['processed']]\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    \n",
    "    # Drop processed (helper column)\n",
    "    df = df.drop(['processed'], axis=1)\n",
    "    print(\"Dataframe as {} rows and {} columns.\".format(*df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = create_features(df_train)\n",
    "df_test = create_features(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell check - TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enchant\n",
    "from enchant.checker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enchant.checker import SpellChecker\n",
    "\n",
    "def spellcheck(corpus):\n",
    "    \"Spellcheck using pyenchant\"\n",
    "    for row in corpus:\n",
    "        chkr = SpellChecker(\"en_US\")\n",
    "        chkr.set_text(row)\n",
    "        for err in chkr:\n",
    "            sug = err.suggest()[0]\n",
    "            err.replace(sug)\n",
    "            print(err.word, sug)\n",
    "        row = chkr.get_text()\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username user name\n",
      "Metallica Metallic\n",
      "GAs Gas\n",
      "FAC AC\n",
      "D'aww D'art\n",
      "colour color\n",
      "UTC CUT\n",
      "ie IE\n",
      "eg g\n",
      "Wikipedia Pediatric\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "0000997932d777bf    Explanation\\nWhy the edits made under my usern...\n",
       "000103f0d9cfb60f    D'aww! He matches this background colour I'm s...\n",
       "000113f07ec002fd    Hey man, I'm really not trying to edit war. It...\n",
       "0001b41b1c6bb37e    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "0001d958c54c6e35    You, sir, are my hero. Any chance you remember...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spellcheck(df_train.comment_text[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "    # convert lines to a single blob of text data = '\\n'.join(lines)\n",
    "    data = '\\n'.join(lines)\n",
    "    # open file\n",
    "    file = open(filename, 'w')\n",
    "    # write text\n",
    "    file.write(data)\n",
    "    # close file\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, path):\n",
    "    full_path = os.path.join(os.path.realpath('..'), path)\n",
    "    df.to_csv(full_path, header=True, index=True)\n",
    "    print('Dataframe ({}, {}) saved as csv.'.format(*df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe (159571, 11) saved as csv.\n",
      "Dataframe (153164, 5) saved as csv.\n"
     ]
    }
   ],
   "source": [
    "save_df(df_train, 'data/processed/train.csv')\n",
    "save_df(df_test, 'data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
