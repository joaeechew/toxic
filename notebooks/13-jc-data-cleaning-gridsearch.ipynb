{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a LSTM single model to text various cleaning steps and impact on score.\n",
    "\n",
    "Results:\n",
    "- Lowercase only improves results\n",
    "- Manual filtering does not help\n",
    "- Removing digits does not help\n",
    "- English only words does not help\n",
    "- Removing english stopwords (NLTK corpus) does not help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'grid_testing_candelete'\n",
    "logging.basicConfig(filename=model_name+'.log',level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.realpath('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import custom transformers\n",
    "\n",
    "path = 'src/features'\n",
    "full_path = os.path.join(dir_path, path)\n",
    "import sys\n",
    "sys.path.append(full_path)\n",
    "from transformers import TextCleaner, KerasProcesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 95851 rows, 7 columns.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/raw/train.csv'\n",
    "\n",
    "full_path = os.path.join(dir_path, path)\n",
    "df_train = pd.read_csv(full_path, header=0, index_col=0)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN with string \"unknown\"\n",
    "df_train.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "test_size = 0.2\n",
    "target = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "corpus = 'comment_text'\n",
    "\n",
    "Xtrain = df_train[corpus][:100]\n",
    "ytrain = df_train[target][:100]\n",
    "\n",
    "\n",
    "# Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=20000\n",
    "max_length=65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam', max_features=max_features, max_length=max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_length))\n",
    "    model.add(Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_path):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_path + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_path + \".h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = CSVLogger(model_name+'.csv', append=True, separator=';')\n",
    "model = KerasClassifier(build_fn=create_model, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('keraser', KerasProcesser(num_words=max_features, maxlen=max_length)),\n",
    "    ('clf', model)\n",
    "])\n",
    "\n",
    "param_grid = {\"cleaner__regex\": ['\\S+'],\n",
    "              \"cleaner__remove_digits\": [False],\n",
    "              \"cleaner__english_only\": [False],\n",
    "              \"cleaner__stop_words\": [None],\n",
    "              \"cleaner__filters\": [r'[!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]'],\n",
    "              \"cleaner__lower\": [False],\n",
    "              \"keraser__num_words\": [max_features],\n",
    "              \"keraser__maxlen\": [max_length],\n",
    "              \"clf__callbacks\": [[csv_logger]]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "50/50 [==============================] - 1s 17ms/step - loss: 0.6918 - acc: 0.6100\n",
      "50/50 [==============================] - 0s 3ms/step\n",
      "50/50 [==============================] - 0s 672us/step\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 1s 22ms/step - loss: 0.6906 - acc: 0.6167\n",
      "50/50 [==============================] - 0s 6ms/step\n",
      "50/50 [==============================] - 0s 671us/step\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 15ms/step - loss: 0.6865 - acc: 0.7867\n",
      "CPU times: user 20.4 s, sys: 1.04 s, total: 21.4 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid = GridSearchCV(p, param_grid=param_grid, cv=2)\n",
    "grid_result = grid.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = grid_result.best_estimator_.named_steps['clf'].model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "model_path = os.path.join(dir_path, 'models', model_name)\n",
    "save_model(trained_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.806667 (0.010000) with: {'cleaner__english_only': False, 'cleaner__filters': '[!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n]', 'cleaner__lower': False, 'cleaner__regex': '\\\\S+', 'cleaner__remove_digits': False, 'cleaner__stop_words': None, 'clf__callbacks': [<keras.callbacks.CSVLogger object at 0x7f328cf3bc18>], 'keraser__maxlen': 65, 'keraser__num_words': 20000} in 4.175341 seconds\n",
      "Best score 0.8066666805744171 with params {'cleaner__english_only': False, 'cleaner__filters': '[!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n]', 'cleaner__lower': False, 'cleaner__regex': '\\\\S+', 'cleaner__remove_digits': False, 'cleaner__stop_words': None, 'clf__callbacks': [<keras.callbacks.CSVLogger object at 0x7f328cf3bc18>], 'keraser__maxlen': 65, 'keraser__num_words': 20000}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "times = grid_result.cv_results_['mean_fit_time']\n",
    "for mean, stdev, param, time in zip(means, stds, params, times):\n",
    "    print(\"%f (%f) with: %r in %f seconds\" % (mean, stdev, param, time))\n",
    "    logging.info(\"%f (%f) with: %r in %f seconds\" % (mean, stdev, param, time))\n",
    "    \n",
    "print(\"Best score {} with params {}\".format(grid_result.best_score_, grid_result.best_params_))\n",
    "logging.info(\"Best score {} with params {}\".format(grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
