{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a LSTM single model to text various cleaning steps and impact on score.\n",
    "\n",
    "Controls:\n",
    "- CNN single model\n",
    "- maxlen: 65\n",
    "- min occurance vocab: 5\n",
    "- glove.6B.100D\n",
    "- epochs: 2\n",
    "- cv: 3\n",
    "- max features 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.realpath('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import custom transformers\n",
    "\n",
    "path = 'src/features'\n",
    "full_path = os.path.join(dir_path, path)\n",
    "import sys\n",
    "sys.path.append(full_path)\n",
    "from transformers import TextCleaner, KerasProcesser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 95851 rows, 7 columns.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/raw/train.csv'\n",
    "\n",
    "full_path = os.path.join(dir_path, path)\n",
    "df_train = pd.read_csv(full_path, header=0, index_col=0)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 226998 rows, 1 columns.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/raw/test.csv'\n",
    "\n",
    "full_path = os.path.join(dir_path, path)\n",
    "df_test = pd.read_csv(full_path, header=0, index_col=0)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN with string \"unknown\"\n",
    "df_train.fillna('unknown',inplace=True)\n",
    "df_test.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "test_size = 0.2\n",
    "target = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "corpus = 'comment_text'\n",
    "\n",
    "X = df_train[corpus]\n",
    "y = df_train[target]\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=20000\n",
    "max_length=65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam', max_features=max_features, max_length=max_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features, 100, input_length=max_length))\n",
    "    model.add(Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(6, activation='sigmoid'))  #multi-label (k-hot encoding)\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def save_model(model, model_path):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(model_path + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(model_path + \".h5\")\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, regex='\\S+', remove_digits=False, english_only=False, stop_words=None, lower=True, filters=None):\n",
    "        self.regex = regex\n",
    "        self.remove_digits = remove_digits\n",
    "        self.english_only = english_only\n",
    "        self.stop_words = stop_words\n",
    "        self.lower = lower\n",
    "        self.filters = filters\n",
    "        \n",
    "    def transform(self, X, *args):\n",
    "        tokenizer = RegexpTokenizer(self.regex)\n",
    "        result = []\n",
    "        for row in X:\n",
    "            tokens = tokenizer.tokenize(row)\n",
    "            if self.filters is not None:\n",
    "                tokens = [re.sub(self.filters, '', t) for t in tokens]\n",
    "            if self.lower:\n",
    "                tokens = [t.lower() for t in tokens]\n",
    "            if self.remove_digits:\n",
    "                tokens = [t for t in tokens if not t.isdigit()]\n",
    "            if self.english_only:\n",
    "                english_words = set(nltk.corpus.words.words())\n",
    "                tokens = [t for t in tokens if t in english_words]\n",
    "            if self.stop_words is not None:\n",
    "                tokens = [t for t in tokens if not t in self.stop_words]\n",
    "            tokens = ' '.join(tokens)\n",
    "            if tokens == '':\n",
    "            \ttokens = 'cleaned'\n",
    "            result.append(tokens)\n",
    "        return result\n",
    "    \n",
    "    def fit(self, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class KerasProcesser(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_words, maxlen):\n",
    "        self.num_words = num_words\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    def transform(self, X, *args):\n",
    "        tokenizer = Tokenizer(self.num_words, lower=False, filters='')\n",
    "        tokenizer.fit_on_texts(X)\n",
    "        # vocab_size = len(tokenizer.word_index) + 1\n",
    "        result = tokenizer.texts_to_sequences(X)\n",
    "        result = pad_sequences(result, maxlen=self.maxlen, padding='post')\n",
    "        return result, tokenizer\n",
    "    \n",
    "    def fit(self, *args):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline([\n",
    "    ('cleaner', TextCleaner()),\n",
    "    ('keraser', KerasProcesser(num_words=max_features, maxlen=max_length))#,\n",
    "])\n",
    "\n",
    "param_grid = {\"cleaner__regex\": ['\\S+'],\n",
    "              \"cleaner__remove_digits\": [False],\n",
    "              \"cleaner__english_only\": [False],\n",
    "              \"cleaner__stop_words\": [None],\n",
    "              \"cleaner__filters\": [r'[!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]'],\n",
    "              \"cleaner__lower\": [True],\n",
    "              \"keraser__num_words\": [max_features],\n",
    "              \"keraser__maxlen\": [max_length]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. {'cleaner__english_only': False, 'cleaner__filters': '[!\"#$%&()*+,-./:;<=>?@[\\\\\\\\]^_`{|}~\\\\t\\\\n]', 'cleaner__lower': True, 'cleaner__regex': '\\\\S+', 'cleaner__remove_digits': False, 'cleaner__stop_words': None, 'keraser__maxlen': 65, 'keraser__num_words': 20000}\n",
      "Epoch 1/2\n",
      "76680/76680 [==============================] - 275s 4ms/step - loss: 0.0827 - acc: 0.9751\n",
      "Epoch 2/2\n",
      "76680/76680 [==============================] - 275s 4ms/step - loss: 0.0540 - acc: 0.9808\n",
      "19171/19171 [==============================] - 11s 571us/step\n",
      "toxic log loss is 0.15848096213519694 .\n",
      "severe_toxic log loss is 0.042444288585190504 .\n",
      "obscene log loss is 0.10191033820340938 .\n",
      "threat log loss is 0.016362210122636837 .\n",
      "insult log loss is 0.111508092123731 .\n",
      "identity_hate log loss is 0.032494380135582854 .\n",
      "Combined log loss: 0.0772000452176246 .\n",
      "Saved model to disk\n",
      "226998/226998 [==============================] - 128s 564us/step\n",
      "CPU times: user 1h 7min 49s, sys: 8min 40s, total: 1h 16min 30s\n",
      "Wall time: 12min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "i = 1\n",
    "\n",
    "for g in ParameterGrid(param_grid):\n",
    "    model_name = 'grid_' + str(i)\n",
    "    logging.basicConfig(filename=model_name+'.log',level=logging.DEBUG)\n",
    "    csv_logger = CSVLogger(model_name+'.csv', append=True, separator=';')\n",
    "    print('{}. {}'.format(i, g))\n",
    "    \n",
    "    p.set_params(**g)\n",
    "    padded_train, t = p.transform(Xtrain)\n",
    "    encoded_test = t.texts_to_sequences(Xtest)\n",
    "    padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')\n",
    "    model.fit(padded_train, ytrain, verbose=1, callbacks=[csv_logger])\n",
    "    \n",
    "    # evaluate model on test dataset\n",
    "    y_pred = model.predict_proba(padded_test, verbose=1)\n",
    "    hold_out_preds = pd.DataFrame(y_pred, index=ytest.index, columns=target)\n",
    "    losses = []\n",
    "\n",
    "    for label in target:\n",
    "        loss = log_loss(ytest[label], hold_out_preds[label])\n",
    "        losses.append(loss)\n",
    "        print(\"{} log loss is {} .\".format(label, loss))\n",
    "\n",
    "    print(\"Combined log loss: {} .\".format(np.mean(losses)))\n",
    "    \n",
    "    # save the model\n",
    "    model_path = os.path.join(dir_path, 'models', model_name)\n",
    "    save_model(model.model, model_path)\n",
    "    \n",
    "    # submissions\n",
    "    encoded_submission = t.texts_to_sequences(df_test[corpus])\n",
    "    padded_submission = pad_sequences(encoded_submission, maxlen=max_length, padding='post')\n",
    "    y_submission = model.predict_proba(padded_submission, verbose=1)\n",
    "    submission = pd.DataFrame(y_submission, index=df_test.index, columns=target)\n",
    "    path = 'data/submissions/' + model_name + '.csv'\n",
    "    full_path = os.path.join(dir_path, path)\n",
    "    submission.to_csv(full_path, header=True, index=True)\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6044863</th>\n",
       "      <td>0.005247</td>\n",
       "      <td>1.891804e-05</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>2.077233e-05</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6102620</th>\n",
       "      <td>0.000906</td>\n",
       "      <td>1.028812e-06</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>4.490527e-07</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14563293</th>\n",
       "      <td>0.004032</td>\n",
       "      <td>4.582534e-06</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>3.926712e-06</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21086297</th>\n",
       "      <td>0.007348</td>\n",
       "      <td>2.681844e-05</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>2.987232e-05</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22982444</th>\n",
       "      <td>0.184843</td>\n",
       "      <td>2.204332e-03</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>3.226800e-03</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.011476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24388733</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>1.451989e-07</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>4.980582e-08</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26195914</th>\n",
       "      <td>0.006653</td>\n",
       "      <td>1.279643e-05</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>9.306658e-06</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31769073</th>\n",
       "      <td>0.006708</td>\n",
       "      <td>1.999508e-05</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>2.029322e-05</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35289443</th>\n",
       "      <td>0.376515</td>\n",
       "      <td>4.511880e-03</td>\n",
       "      <td>0.069746</td>\n",
       "      <td>7.257162e-03</td>\n",
       "      <td>0.111367</td>\n",
       "      <td>0.022983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38393350</th>\n",
       "      <td>0.017252</td>\n",
       "      <td>4.490855e-05</td>\n",
       "      <td>0.003229</td>\n",
       "      <td>3.448565e-05</td>\n",
       "      <td>0.003556</td>\n",
       "      <td>0.000468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51720630</th>\n",
       "      <td>0.009199</td>\n",
       "      <td>2.319719e-05</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>2.202588e-05</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.000226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52808210</th>\n",
       "      <td>0.025662</td>\n",
       "      <td>7.822687e-05</td>\n",
       "      <td>0.005311</td>\n",
       "      <td>5.328620e-05</td>\n",
       "      <td>0.005165</td>\n",
       "      <td>0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53780387</th>\n",
       "      <td>0.009117</td>\n",
       "      <td>3.616265e-05</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>4.129131e-05</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55969236</th>\n",
       "      <td>0.001549</td>\n",
       "      <td>1.710054e-06</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>1.146542e-06</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59321043</th>\n",
       "      <td>0.039212</td>\n",
       "      <td>1.478155e-04</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>1.603943e-04</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>0.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59993753</th>\n",
       "      <td>0.000675</td>\n",
       "      <td>5.525255e-07</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>2.678935e-07</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60087415</th>\n",
       "      <td>0.002055</td>\n",
       "      <td>2.880437e-06</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>1.617065e-06</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62246374</th>\n",
       "      <td>0.063849</td>\n",
       "      <td>7.564927e-04</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1.038962e-03</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63082469</th>\n",
       "      <td>0.000782</td>\n",
       "      <td>6.464310e-07</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>4.424894e-07</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66675140</th>\n",
       "      <td>0.026154</td>\n",
       "      <td>1.158716e-04</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>1.222392e-04</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68336055</th>\n",
       "      <td>0.135916</td>\n",
       "      <td>6.307600e-04</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>7.438404e-04</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.004712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70790434</th>\n",
       "      <td>0.024078</td>\n",
       "      <td>1.012825e-04</td>\n",
       "      <td>0.004935</td>\n",
       "      <td>1.211759e-04</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.000814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71559114</th>\n",
       "      <td>0.002100</td>\n",
       "      <td>3.078128e-06</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>2.377810e-06</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72407499</th>\n",
       "      <td>0.001902</td>\n",
       "      <td>3.152975e-06</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>1.520550e-06</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75557079</th>\n",
       "      <td>0.063849</td>\n",
       "      <td>7.564927e-04</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1.038962e-03</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75694081</th>\n",
       "      <td>0.009055</td>\n",
       "      <td>2.338566e-05</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>2.487606e-05</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.000216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82999985</th>\n",
       "      <td>0.025668</td>\n",
       "      <td>7.562480e-05</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>8.019523e-05</td>\n",
       "      <td>0.004810</td>\n",
       "      <td>0.000688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84135100</th>\n",
       "      <td>0.007945</td>\n",
       "      <td>2.917116e-05</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>3.182564e-05</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88993345</th>\n",
       "      <td>0.181537</td>\n",
       "      <td>1.490114e-03</td>\n",
       "      <td>0.030252</td>\n",
       "      <td>2.299688e-03</td>\n",
       "      <td>0.046393</td>\n",
       "      <td>0.008989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90125467</th>\n",
       "      <td>0.051607</td>\n",
       "      <td>2.847850e-04</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>3.866636e-04</td>\n",
       "      <td>0.010879</td>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999890906666</th>\n",
       "      <td>0.005684</td>\n",
       "      <td>1.296607e-05</td>\n",
       "      <td>0.001343</td>\n",
       "      <td>8.501547e-06</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999891110310</th>\n",
       "      <td>0.051093</td>\n",
       "      <td>3.597397e-04</td>\n",
       "      <td>0.009558</td>\n",
       "      <td>4.717816e-04</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.002388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999901299717</th>\n",
       "      <td>0.004119</td>\n",
       "      <td>1.132407e-05</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>1.126061e-05</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999902107116</th>\n",
       "      <td>0.005336</td>\n",
       "      <td>1.299079e-05</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>1.221202e-05</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999902754612</th>\n",
       "      <td>0.002281</td>\n",
       "      <td>2.625867e-06</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>1.994990e-06</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999904175486</th>\n",
       "      <td>0.001786</td>\n",
       "      <td>1.530691e-06</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>1.201586e-06</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999905240338</th>\n",
       "      <td>0.005535</td>\n",
       "      <td>7.895412e-06</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>7.754673e-06</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999906741497</th>\n",
       "      <td>0.008103</td>\n",
       "      <td>1.826671e-05</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>1.764230e-05</td>\n",
       "      <td>0.001385</td>\n",
       "      <td>0.000192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999911717743</th>\n",
       "      <td>0.005069</td>\n",
       "      <td>7.932893e-06</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>7.197455e-06</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999918907071</th>\n",
       "      <td>0.063849</td>\n",
       "      <td>7.564927e-04</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1.038962e-03</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999920895395</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>8.117414e-06</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>5.072487e-06</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999921181305</th>\n",
       "      <td>0.025815</td>\n",
       "      <td>7.133937e-05</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>7.612868e-05</td>\n",
       "      <td>0.004513</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999921616383</th>\n",
       "      <td>0.093847</td>\n",
       "      <td>7.299821e-04</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>9.501667e-04</td>\n",
       "      <td>0.021998</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999924773922</th>\n",
       "      <td>0.024702</td>\n",
       "      <td>1.526872e-04</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>1.791195e-04</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>0.000945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999927268950</th>\n",
       "      <td>0.011865</td>\n",
       "      <td>3.869448e-05</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>2.424649e-05</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>0.000249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999937028166</th>\n",
       "      <td>0.001691</td>\n",
       "      <td>1.607422e-06</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>1.143019e-06</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999939655437</th>\n",
       "      <td>0.000909</td>\n",
       "      <td>8.547923e-07</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>6.149323e-07</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999941555776</th>\n",
       "      <td>0.040456</td>\n",
       "      <td>2.351080e-04</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>3.075727e-04</td>\n",
       "      <td>0.009042</td>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999942678927</th>\n",
       "      <td>0.002378</td>\n",
       "      <td>3.477034e-06</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>1.683221e-06</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999943838330</th>\n",
       "      <td>0.056188</td>\n",
       "      <td>4.820703e-04</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>6.038274e-04</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.002728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999956516304</th>\n",
       "      <td>0.063849</td>\n",
       "      <td>7.564927e-04</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1.038962e-03</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999960677672</th>\n",
       "      <td>0.001083</td>\n",
       "      <td>9.696149e-07</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>7.234398e-07</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999963214716</th>\n",
       "      <td>0.003464</td>\n",
       "      <td>4.910712e-06</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>2.975914e-06</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999964222196</th>\n",
       "      <td>0.011883</td>\n",
       "      <td>2.939978e-05</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>2.696328e-05</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999964949747</th>\n",
       "      <td>0.001966</td>\n",
       "      <td>2.577096e-06</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>1.315568e-06</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999966872214</th>\n",
       "      <td>0.063849</td>\n",
       "      <td>7.564927e-04</td>\n",
       "      <td>0.014071</td>\n",
       "      <td>1.038962e-03</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999968525410</th>\n",
       "      <td>0.019772</td>\n",
       "      <td>3.919863e-05</td>\n",
       "      <td>0.003070</td>\n",
       "      <td>3.515647e-05</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999980053494</th>\n",
       "      <td>0.046177</td>\n",
       "      <td>3.635516e-04</td>\n",
       "      <td>0.009277</td>\n",
       "      <td>4.540951e-04</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.002154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999980680364</th>\n",
       "      <td>0.076921</td>\n",
       "      <td>6.008487e-04</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>8.278792e-04</td>\n",
       "      <td>0.015755</td>\n",
       "      <td>0.003795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997819802</th>\n",
       "      <td>0.017515</td>\n",
       "      <td>4.410234e-05</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>3.519276e-05</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.000409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226998 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 toxic  severe_toxic   obscene        threat    insult  \\\n",
       "id                                                                       \n",
       "6044863       0.005247  1.891804e-05  0.001366  2.077233e-05  0.000644   \n",
       "6102620       0.000906  1.028812e-06  0.000300  4.490527e-07  0.000088   \n",
       "14563293      0.004032  4.582534e-06  0.000757  3.926712e-06  0.000587   \n",
       "21086297      0.007348  2.681844e-05  0.001776  2.987232e-05  0.001171   \n",
       "22982444      0.184843  2.204332e-03  0.030813  3.226800e-03  0.043333   \n",
       "24388733      0.000150  1.451989e-07  0.000068  4.980582e-08  0.000011   \n",
       "26195914      0.006653  1.279643e-05  0.001468  9.306658e-06  0.001113   \n",
       "31769073      0.006708  1.999508e-05  0.001528  2.029322e-05  0.001116   \n",
       "35289443      0.376515  4.511880e-03  0.069746  7.257162e-03  0.111367   \n",
       "38393350      0.017252  4.490855e-05  0.003229  3.448565e-05  0.003556   \n",
       "51720630      0.009199  2.319719e-05  0.001711  2.202588e-05  0.001409   \n",
       "52808210      0.025662  7.822687e-05  0.005311  5.328620e-05  0.005165   \n",
       "53780387      0.009117  3.616265e-05  0.002122  4.129131e-05  0.001339   \n",
       "55969236      0.001549  1.710054e-06  0.000310  1.146542e-06  0.000204   \n",
       "59321043      0.039212  1.478155e-04  0.006138  1.603943e-04  0.007932   \n",
       "59993753      0.000675  5.525255e-07  0.000163  2.678935e-07  0.000060   \n",
       "60087415      0.002055  2.880437e-06  0.000490  1.617065e-06  0.000253   \n",
       "62246374      0.063849  7.564927e-04  0.014071  1.038962e-03  0.012328   \n",
       "63082469      0.000782  6.464310e-07  0.000161  4.424894e-07  0.000084   \n",
       "66675140      0.026154  1.158716e-04  0.005110  1.222392e-04  0.004946   \n",
       "68336055      0.135916  6.307600e-04  0.015904  7.438404e-04  0.032202   \n",
       "70790434      0.024078  1.012825e-04  0.004935  1.211759e-04  0.004566   \n",
       "71559114      0.002100  3.078128e-06  0.000456  2.377810e-06  0.000276   \n",
       "72407499      0.001902  3.152975e-06  0.000599  1.520550e-06  0.000220   \n",
       "75557079      0.063849  7.564927e-04  0.014071  1.038962e-03  0.012328   \n",
       "75694081      0.009055  2.338566e-05  0.001987  2.487606e-05  0.001367   \n",
       "82999985      0.025668  7.562480e-05  0.003886  8.019523e-05  0.004810   \n",
       "84135100      0.007945  2.917116e-05  0.001784  3.182564e-05  0.001059   \n",
       "88993345      0.181537  1.490114e-03  0.030252  2.299688e-03  0.046393   \n",
       "90125467      0.051607  2.847850e-04  0.009408  3.866636e-04  0.010879   \n",
       "...                ...           ...       ...           ...       ...   \n",
       "999890906666  0.005684  1.296607e-05  0.001343  8.501547e-06  0.000724   \n",
       "999891110310  0.051093  3.597397e-04  0.009558  4.717816e-04  0.010195   \n",
       "999901299717  0.004119  1.132407e-05  0.001056  1.126061e-05  0.000578   \n",
       "999902107116  0.005336  1.299079e-05  0.001054  1.221202e-05  0.000760   \n",
       "999902754612  0.002281  2.625867e-06  0.000447  1.994990e-06  0.000318   \n",
       "999904175486  0.001786  1.530691e-06  0.000322  1.201586e-06  0.000207   \n",
       "999905240338  0.005535  7.895412e-06  0.001014  7.754673e-06  0.000759   \n",
       "999906741497  0.008103  1.826671e-05  0.001586  1.764230e-05  0.001385   \n",
       "999911717743  0.005069  7.932893e-06  0.000941  7.197455e-06  0.000746   \n",
       "999918907071  0.063849  7.564927e-04  0.014071  1.038962e-03  0.012328   \n",
       "999920895395  0.003097  8.117414e-06  0.000902  5.072487e-06  0.000481   \n",
       "999921181305  0.025815  7.133937e-05  0.004157  7.612868e-05  0.004513   \n",
       "999921616383  0.093847  7.299821e-04  0.016141  9.501667e-04  0.021998   \n",
       "999924773922  0.024702  1.526872e-04  0.005357  1.791195e-04  0.004021   \n",
       "999927268950  0.011865  3.869448e-05  0.003311  2.424649e-05  0.001881   \n",
       "999937028166  0.001691  1.607422e-06  0.000366  1.143019e-06  0.000198   \n",
       "999939655437  0.000909  8.547923e-07  0.000208  6.149323e-07  0.000103   \n",
       "999941555776  0.040456  2.351080e-04  0.008683  3.075727e-04  0.009042   \n",
       "999942678927  0.002378  3.477034e-06  0.000644  1.683221e-06  0.000276   \n",
       "999943838330  0.056188  4.820703e-04  0.011226  6.038274e-04  0.010889   \n",
       "999956516304  0.063849  7.564927e-04  0.014071  1.038962e-03  0.012328   \n",
       "999960677672  0.001083  9.696149e-07  0.000228  7.234398e-07  0.000118   \n",
       "999963214716  0.003464  4.910712e-06  0.000859  2.975914e-06  0.000447   \n",
       "999964222196  0.011883  2.939978e-05  0.002184  2.696328e-05  0.002095   \n",
       "999964949747  0.001966  2.577096e-06  0.000491  1.315568e-06  0.000226   \n",
       "999966872214  0.063849  7.564927e-04  0.014071  1.038962e-03  0.012328   \n",
       "999968525410  0.019772  3.919863e-05  0.003070  3.515647e-05  0.004097   \n",
       "999980053494  0.046177  3.635516e-04  0.009277  4.540951e-04  0.008756   \n",
       "999980680364  0.076921  6.008487e-04  0.013341  8.278792e-04  0.015755   \n",
       "999997819802  0.017515  4.410234e-05  0.003198  3.519276e-05  0.003053   \n",
       "\n",
       "              identity_hate  \n",
       "id                           \n",
       "6044863            0.000144  \n",
       "6102620            0.000011  \n",
       "14563293           0.000066  \n",
       "21086297           0.000235  \n",
       "22982444           0.011476  \n",
       "24388733           0.000002  \n",
       "26195914           0.000147  \n",
       "31769073           0.000194  \n",
       "35289443           0.022983  \n",
       "38393350           0.000468  \n",
       "51720630           0.000226  \n",
       "52808210           0.000614  \n",
       "53780387           0.000287  \n",
       "55969236           0.000025  \n",
       "59321043           0.001231  \n",
       "59993753           0.000007  \n",
       "60087415           0.000034  \n",
       "62246374           0.003739  \n",
       "63082469           0.000010  \n",
       "66675140           0.000848  \n",
       "68336055           0.004712  \n",
       "70790434           0.000814  \n",
       "71559114           0.000036  \n",
       "72407499           0.000027  \n",
       "75557079           0.003739  \n",
       "75694081           0.000216  \n",
       "82999985           0.000688  \n",
       "84135100           0.000230  \n",
       "88993345           0.008989  \n",
       "90125467           0.002141  \n",
       "...                     ...  \n",
       "999890906666       0.000109  \n",
       "999891110310       0.002388  \n",
       "999901299717       0.000105  \n",
       "999902107116       0.000128  \n",
       "999902754612       0.000037  \n",
       "999904175486       0.000022  \n",
       "999905240338       0.000094  \n",
       "999906741497       0.000192  \n",
       "999911717743       0.000090  \n",
       "999918907071       0.003739  \n",
       "999920895395       0.000075  \n",
       "999921181305       0.000616  \n",
       "999921616383       0.004602  \n",
       "999924773922       0.000945  \n",
       "999927268950       0.000249  \n",
       "999937028166       0.000024  \n",
       "999939655437       0.000013  \n",
       "999941555776       0.001698  \n",
       "999942678927       0.000034  \n",
       "999943838330       0.002728  \n",
       "999956516304       0.003739  \n",
       "999960677672       0.000014  \n",
       "999963214716       0.000054  \n",
       "999964222196       0.000267  \n",
       "999964949747       0.000028  \n",
       "999966872214       0.003739  \n",
       "999968525410       0.000433  \n",
       "999980053494       0.002154  \n",
       "999980680364       0.003795  \n",
       "999997819802       0.000409  \n",
       "\n",
       "[226998 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
