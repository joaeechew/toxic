{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently stacks using weighted average on predicted submissions files.\n",
    "\n",
    "To do:\n",
    "- Use folds in the initial layers and train a stacking a layer (boosted tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 95851 rows, 7 columns.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/raw/train.csv'\n",
    "\n",
    "full_path = os.path.join(dir_path, path)\n",
    "df_train = pd.read_csv(full_path, header=0, index_col=0)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 226998 rows, 1 columns.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/raw/test.csv'\n",
    "\n",
    "full_path = os.path.join(dir_path, path)\n",
    "df_test = pd.read_csv(full_path, header=0, index_col=0)\n",
    "print(\"Dataset has {} rows, {} columns.\".format(*df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill NaN with string \"unknown\"\n",
    "df_train.fillna('unknown',inplace=True)\n",
    "df_test.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "test_size = 0.2\n",
    "target = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "corpus = 'comment_text'\n",
    "\n",
    "X = df_train[corpus]\n",
    "y = df_train[target]\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and predict using trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import CSVLogger\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "def load_model(model_name):\n",
    "    # load json and create model\n",
    "    json_file = open(model_name+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(model_name+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "model_name = ''\n",
    "loaded_model = load_model(model_name)\n",
    "y_pred_LSTM = loaded_model.predict(padded_test, verbose=1)\n",
    "\n",
    "# LR\n",
    "model_name = ''\n",
    "loaded_model = load_model(model_name)\n",
    "y_pred_LR = loaded_model.predict(padded_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_data(path):\n",
    "    full_path = os.path.join(os.path.realpath('..'), path)\n",
    "    df = pd.read_csv(full_path, header=0, index_col=0)\n",
    "    print(\"Dataset has {} rows, {} columns.\".format(*df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 153164 rows, 6 columns.\n",
      "Dataset has 153164 rows, 6 columns.\n"
     ]
    }
   ],
   "source": [
    "LR = load_data('data/submissions/LR.csv')\n",
    "LSTM = load_data('data/submissions/LSTM1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Weighted averaging\n",
    "score_lr = 0.188\n",
    "score_lstm = 0.065\n",
    "total = score_lr + score_lstm\n",
    "df_stack = (1-score_lr/total)*LR + (1-score_lstm/total)*LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>0.700484</td>\n",
       "      <td>0.143361</td>\n",
       "      <td>0.595480</td>\n",
       "      <td>0.026594</td>\n",
       "      <td>0.549922</td>\n",
       "      <td>0.346802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0.021168</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.008129</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>0.016195</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.000172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>0.030189</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "id                                                                       \n",
       "00001cee341fdb12  0.700484      0.143361  0.595480  0.026594  0.549922   \n",
       "0000247867823ef7  0.021168      0.000261  0.008129  0.000247  0.017907   \n",
       "00013b17ad220c46  0.016195      0.000409  0.001198  0.000103  0.001266   \n",
       "00017563c3f7919a  0.001309      0.000315  0.001791  0.000108  0.000926   \n",
       "00017695ad8997eb  0.030189      0.000776  0.003190  0.000229  0.000967   \n",
       "\n",
       "                  identity_hate  \n",
       "id                               \n",
       "00001cee341fdb12       0.346802  \n",
       "0000247867823ef7       0.008166  \n",
       "00013b17ad220c46       0.000253  \n",
       "00017563c3f7919a       0.000172  \n",
       "00017695ad8997eb       0.000272  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'LR_LSTM'\n",
    "path = 'data/submissions/' + model_name + '.csv'\n",
    "full_path = os.path.join(os.path.realpath('..'), path)\n",
    "df_stack.to_csv(full_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic log loss is 0.11489777604597493 .\n",
      "severe_toxic log loss is 0.023760985902965184 .\n",
      "obscene log loss is 0.0592291762449135 .\n",
      "threat log loss is 0.012569925774706866 .\n",
      "insult log loss is 0.06995742146136677 .\n",
      "identity_hate log loss is 0.02375914206328263 .\n",
      "Combined log loss: 0.05122455304682492 .\n"
     ]
    }
   ],
   "source": [
    "# Create stacking layer training set - LSTM predictions with true labels\n",
    "stacking = pd.concat([predictions[0], predictions[1]])\n",
    "for col in stacking.columns:\n",
    "    stacking.rename(columns={col: col+'_LSTM'}, inplace=True)\n",
    "stacking = stacking.join(X)\n",
    "stacking = stacking.join(y)\n",
    "\n",
    "# Evaluate 1st layer\n",
    "for label in target:\n",
    "    loss = log_loss(stacking[label], stacking[label+'_LSTM'])\n",
    "    losses.append(loss)\n",
    "    print(\"{} log loss is {} .\".format(label, loss))\n",
    "print(\"Combined log loss: {} .\".format(np.mean(losses)))\n",
    "\n",
    "# Save file\n",
    "path = 'data/processed/stacking.csv'\n",
    "full_path = os.path.join(dir_path, path)\n",
    "ytest.to_csv(full_path, header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use HOO to evaluate first layer combined log loss"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
